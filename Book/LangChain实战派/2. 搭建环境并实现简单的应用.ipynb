{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa64eb6-6355-49e5-ab2a-d3ebc0dc1f67",
   "metadata": {},
   "source": [
    "# 2. 搭建环境并实现简单的应用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53485355-d82a-4451-be4a-429d77de0a8d",
   "metadata": {},
   "source": [
    "## 2.1 搭建环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ecc35a0-7054-433f-85eb-5446ba0c3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curl -fsSL https://ollama.com/install.sh | sh\n",
    "# ollama pull gpt-oss:20b\n",
    "# venv/bin/pip3 install langchain==0.1.14 langchain-community==0.0.38 langchain-core==0.1.53 langchain-openai==0.1.7\n",
    "\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ac184d-69ee-4af7-9a82-4c9383e08858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.14'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac0cc6-e4d5-4716-9a87-c41681430953",
   "metadata": {},
   "source": [
    "## 2.2 实现问答应用——基于基础模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6538ee05-4920-4f0f-927e-8c58cb16a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"gpt-oss:20b\")                      # 如果Ollama在本机，可以这样访问，但是当前环境的Ollama在局域网的另一台主机上(192.168.1.211)\n",
    "print(llm.predict(\"AI会对人类文明产生深远的影响吗？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d679c7f-42dc-411a-a879-0fa669eab3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "class RemoteOllama:\n",
    "    def __init__(self, host: str, model: str = \"gpt-oss:20b\"):\n",
    "        self.host = host\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, prompt: str) -> str:\n",
    "        url = f\"http://{self.host}:11434/v1/completions\"  # Ollama 远程 API\n",
    "        payload = {\"model\": self.model, \"prompt\": prompt, \"max_tokens\": 200}\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "        response.raise_for_status()\n",
    "        return response.json().get(\"completion\", \"\")\n",
    "\n",
    "# 使用示例\n",
    "llm = RemoteOllama(host=\"192.168.1.211\", model=\"gpt-oss:20b\")\n",
    "result = llm.predict(\"AI会对人类文明产生深远的影响吗？\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1461526-ab34-4d3c-a498-8240b836f50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llm = RemoteOllama(host=\"192.168.1.211\", model=\"gpt-oss:20b\")\n",
    "# print(llm.generate([\"AI会对人类文明产生深远的影响吗？\"]).generations[0][0].text)\n",
    "# print(llm.predict(\"AI会对人类文明产生深远的影响吗？\"))\n",
    "result = llm(\"AI会对人类文明产生深远的影响吗？\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21efd998-9394-4ef5-947e-0bfe549160cb",
   "metadata": {},
   "source": [
    "## 2.3 实现翻译应用——基于聊天模型和指令模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b458407-a240-4d18-8761-241797f57bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26242/3516977631.py:9: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  chat = ChatOllama(model=\"qwen:1.8b\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='人工智能（AI）将在未来几年对人类文明产生深远影响。' additional_kwargs={} response_metadata={'model': 'qwen:1.8b', 'created_at': '2025-02-17T03:43:09.24743409Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 4081473876, 'load_duration': 24843276, 'prompt_eval_count': 49, 'prompt_eval_duration': 575000000, 'eval_count': 15, 'eval_duration': 3477000000} id='run-a656c02b-4888-434a-8aa4-9603bc8197c2-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# 创建一个ChatOllama对象\n",
    "chat = ChatOllama(model=\"qwen:1.8b\")\n",
    "# 配置聊天模板信息\n",
    "template = \"你是一个翻译助理，请将用户输入的内容由{input_language}直接翻译为{output_language}.\"  # 设置翻译任务的基本指令\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)                     # 基于template创建系统消息指令，向聊天模型明确翻译任务要求\n",
    "human_template = \"{text}\"                                                                       # 简单定义人类校址指令模板，仅包含待翻译文本\n",
    "human_massage_prompt = HumanMessagePromptTemplate.from_template(human_template)                 # 定义人类消息指令\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_massage_prompt])   # 将系统消息指令和人类消息指令组合为完整的聊天指令，用于与聊天模型交互\n",
    "\n",
    "# 输入信息并获取翻译结果\n",
    "print(chat.invoke(chat_prompt.format_prompt(input_language=\"英语\",\n",
    "                                            output_language=\"中文\",\n",
    "                                            text=\"Artificial Intelligence (AI) will have a profound impact on human civilization in the coming years.\").to_messages()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e32ac6c-b2f7-4961-a936-9edced440fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
