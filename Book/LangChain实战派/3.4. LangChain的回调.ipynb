{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e894ce36-f0ce-46ad-9566-1987a2c82534",
   "metadata": {},
   "source": [
    "# 3. LangChain基础"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d4cf15-7f64-42dd-80b3-88c9842fd55e",
   "metadata": {},
   "source": [
    "## 3.4. LangChain的回调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a595a2-84be-4928-9df8-5cabb6cfbd92",
   "metadata": {},
   "source": [
    "### 3.4.2. 认识异步回调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85fbe96-60a0-4a2c-8fb5-49fc7813973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_502005/4027783183.py:45: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  chat = ChatOllama(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zzzz....\n",
      "LLM正在启动\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 北京\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 是中国\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 的\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 首都\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ，\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 拥有\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 丰富的\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 特产\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 。\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 以下\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 是一\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 些\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 在北京\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 常见的\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 特产\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ：\n",
      "\n",
      "\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 1\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: .\n",
      "正在 thread_pool_executor 中调用同步处理程序: token:  糖\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 果\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ：\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 北京\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 的\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 糖果\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 种类\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 繁\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 多\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ，\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 如\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 枣\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 泥\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 、\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 豆\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 沙\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 、\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 芝麻\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 糖\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 等\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 。\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 其中\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ，\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 枣\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 泥\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 和\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 豆\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 沙\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 是\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 北京\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 传统\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 糕\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 点\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ，\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 而\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 芝麻\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 糖\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 则\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 是一种\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 新兴\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 的\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 甜\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 品\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 。\n",
      "\n",
      "\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 2\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: .\n",
      "正在 thread_pool_executor 中调用同步处理程序: token:  面\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 食\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ：\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 北京\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 的\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 面\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 食\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 种类\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 丰富\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ，\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 包括\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 馒头\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 、\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 包子\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 、\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 烙\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 饼\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 、\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 炸\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 酱\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 面\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 等\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 。\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 其中\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ，\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 馒头\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 和\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 包子\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 是中国\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 北方\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 的传统\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 面\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 食\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ，\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 而\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 烙\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 饼\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 和\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 炸\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 酱\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 面\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 则是\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 北京\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 地区\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 新兴\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 的\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 面\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 食\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 。\n",
      "\n",
      "\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 3\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: .\n",
      "正在 thread_pool_executor 中调用同步处理程序: token:  茶\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 叶\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ：\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 北京\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 是\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 全国\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 最大的\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 茶叶\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 产区\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 之一\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ，\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 拥有\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 丰富的\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 茶\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 树\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 资源\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 和\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 独特的\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 茶\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 文化\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 。\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 其中\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ，\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 龙\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 井\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 茶\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 、\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 碧\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 螺\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 春\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 茶\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 、\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 白\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 毫\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 银\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 针\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 茶\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 等\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 都是\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 北京\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 地区的\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 著名\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 茶叶\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 品种\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 。\n",
      "\n",
      "\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 4\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: .\n",
      "正在 thread_pool_executor 中调用同步处理程序: token:  瓷\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 器\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ：\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 北京\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 是中国\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 的\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 首都\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ，\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 也是\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 中国\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 瓷器\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 的重要\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 产地\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 之一\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 。\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 其中\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: ，\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 青\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 花\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 瓷\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 、\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 粉\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 彩\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 瓷\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 、\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 五\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 彩\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 瓷\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 等\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 都是\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 北京\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 地区\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 著名的\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 瓷器\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 品种\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: 。\n",
      "正在 thread_pool_executor 中调用同步处理程序: token: \n",
      "zzzz....\n",
      "LLM结束\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text='北京是中国的首都，拥有丰富的特产。以下是一些在北京常见的特产：\\n\\n1. 糖果：北京的糖果种类繁多，如枣泥、豆沙、芝麻糖等。其中，枣泥和豆沙是北京传统糕点，而芝麻糖则是一种新兴的甜品。\\n\\n2. 面食：北京的面食种类丰富，包括馒头、包子、烙饼、炸酱面等。其中，馒头和包子是中国北方的传统面食，而烙饼和炸酱面则是北京地区新兴的面食。\\n\\n3. 茶叶：北京是全国最大的茶叶产区之一，拥有丰富的茶树资源和独特的茶文化。其中，龙井茶、碧螺春茶、白毫银针茶等都是北京地区的著名茶叶品种。\\n\\n4. 瓷器：北京是中国的首都，也是中国瓷器的重要产地之一。其中，青花瓷、粉彩瓷、五彩瓷等都是北京地区著名的瓷器品种。', generation_info={'model': 'qwen:1.8b', 'created_at': '2025-02-22T09:20:27.223424119Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 53251345137, 'load_duration': 2082765641, 'prompt_eval_count': 12, 'prompt_eval_duration': 401000000, 'eval_count': 207, 'eval_duration': 50765000000}, message=AIMessage(content='北京是中国的首都，拥有丰富的特产。以下是一些在北京常见的特产：\\n\\n1. 糖果：北京的糖果种类繁多，如枣泥、豆沙、芝麻糖等。其中，枣泥和豆沙是北京传统糕点，而芝麻糖则是一种新兴的甜品。\\n\\n2. 面食：北京的面食种类丰富，包括馒头、包子、烙饼、炸酱面等。其中，馒头和包子是中国北方的传统面食，而烙饼和炸酱面则是北京地区新兴的面食。\\n\\n3. 茶叶：北京是全国最大的茶叶产区之一，拥有丰富的茶树资源和独特的茶文化。其中，龙井茶、碧螺春茶、白毫银针茶等都是北京地区的著名茶叶品种。\\n\\n4. 瓷器：北京是中国的首都，也是中国瓷器的重要产地之一。其中，青花瓷、粉彩瓷、五彩瓷等都是北京地区著名的瓷器品种。', additional_kwargs={}, response_metadata={'model': 'qwen:1.8b', 'created_at': '2025-02-22T09:20:27.223424119Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 53251345137, 'load_duration': 2082765641, 'prompt_eval_count': 12, 'prompt_eval_duration': 401000000, 'eval_count': 207, 'eval_duration': 50765000000}, id='run-0f708849-521e-4e6e-a0b1-3a50b2ccd9d0-0'))]], llm_output={}, run=[RunInfo(run_id=UUID('0f708849-521e-4e6e-a0b1-3a50b2ccd9d0'))], type='LLMResult')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import Any, Dict, List\n",
    "from langchain.callbacks.base import AsyncCallbackHandler, BaseCallbackHandler\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.outputs import LLMResult\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "class MyCustomSyncHandler(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        print(f\"正在 thread_pool_executor 中调用同步处理程序: token: {token}\")\n",
    "\n",
    "class MyCustomAsyncHandler(AsyncCallbackHandler):\n",
    "    \"\"\"可用于处理来自LangChain的回调异步回调处理程序。\"\"\"\n",
    "    async def on_llm_start(\n",
    "        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any) -> None:\n",
    "        \"\"\"在链开始时运行。\"\"\"\n",
    "        print(\"zzzz....\")\n",
    "        await asyncio.sleep(0.3)\n",
    "        class_name = serialized[\"name\"]\n",
    "        print(\"LLM正在启动\")\n",
    "\n",
    "    async def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:\n",
    "        \"\"\"在链结束时运行。\"\"\"\n",
    "        print(\"zzzz....\")\n",
    "        await asyncio.sleep(0.3)\n",
    "        print(\"LLM结束\")\n",
    "\n",
    "\n",
    "# 为了启用流式传输，在ChatModel()构造函数中传入streaming=True\n",
    "# 此外，还传入了一个包含自定义处理程序的列表\n",
    "\n",
    "\"\"\"\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:11434/v1\"\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key = openai_api_key, \n",
    "    openai_api_base = openai_api_base,\n",
    "    temperature=0, \n",
    "    streaming=True,\n",
    "    callbacks=[MyCustomSyncHandler(), MyCustomAsyncHandler()],)\n",
    "\"\"\"\n",
    "\n",
    "chat = ChatOllama(\n",
    "    model=\"qwen:1.8b\",\n",
    "    temperature=0, \n",
    "    streaming=True,\n",
    "    callbacks=[MyCustomSyncHandler(), MyCustomAsyncHandler()],)\n",
    "\n",
    "await chat.agenerate([[HumanMessage(content=\"告诉我北京的特产\")]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce26f35a-fd34-4c3b-8f97-43b7ffacf866",
   "metadata": {},
   "source": [
    "### 3.4.4. 自定义回调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e69cc7-e35e-46c9-b43a-1c20199c3191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_502005/2436596163.py:17: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chat([HumanMessage(content=\"中国首都是？\")])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自定义回调处理器, token: 北京\n",
      "自定义回调处理器, token: 。\n",
      "自定义回调处理器, token: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='北京。', additional_kwargs={}, response_metadata={'model': 'qwen:1.8b', 'created_at': '2025-02-22T09:21:19.66625431Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 732771314, 'load_duration': 24750644, 'prompt_eval_count': 12, 'prompt_eval_duration': 328000000, 'eval_count': 3, 'eval_duration': 378000000}, id='run-21a31dea-52f4-43de-a543-118cbdb6cd09-0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "class MyCustomHandler(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        print(f\"自定义回调处理器, token: {token}\")\n",
    "\n",
    "\"\"\"\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:11434/v1\"\n",
    "chat = ChatOpenAI(max_tokens=25, streaming=True,openai_api_key = openai_api_key,openai_api_base = openai_api_base, callbacks=[MyCustomHandler()])\n",
    "\"\"\"\n",
    "\n",
    "chat = ChatOllama(model=\"qwen:1.8b\", max_tokens=25, streaming=True, callbacks=[MyCustomHandler()])\n",
    "chat([HumanMessage(content=\"中国首都是？\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2f0fe0-23dd-4866-8fc6-46bfa3a7d99d",
   "metadata": {},
   "source": [
    "### 3.4.5. 使用回调记录日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34cc5664-3473-4e13-b570-02e6bfec0ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_502005/2848775976.py:22: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler], verbose=True)\n",
      "/tmp/ipykernel_502005/2848775976.py:23: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = chain.run(number=1)\n",
      "Error in FileCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m1 + 1 = \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-22 04:21:24.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1m2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import FileCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from loguru import logger\n",
    "\n",
    "logfile = \"output.log\"\n",
    "logger.add(logfile, colorize=True, enqueue=True)\n",
    "handler = FileCallbackHandler(logfile)\n",
    "\n",
    "\"\"\"\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:11434/v1\"\n",
    "llm = OpenAI(openai_api_key = openai_api_key, openai_api_base = openai_api_base,)\n",
    "\"\"\"\n",
    "llm = ChatOllama(model=\"qwen:1.8b\")\n",
    "prompt = PromptTemplate.from_template(\"1 + {number} = \")\n",
    "\n",
    "# 这个链将同时向标准输出打印（因为 verbose=True）并写入 'output.log'\n",
    "# 如果 verbose=False，FileCallbackHandler 仍会写入 'output.log'\n",
    "chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler], verbose=True)\n",
    "answer = chain.run(number=1)\n",
    "logger.info(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690784cf-98b5-4db2-a981-ec56107ff1e1",
   "metadata": {},
   "source": [
    "### 3.4.6. 处理多个回调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33565295-1505-40d5-861a-c330492e9472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_502005/2776638409.py:42: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"qwen:1.8b\", callbacks=[handler2])\n",
      "/tmp/ipykernel_502005/2776638409.py:44: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n",
      "Error in MyCustomHandlerOne.on_chain_start callback: TypeError(\"'NoneType' object is not subscriptable\")\n",
      "Error in MyCustomHandlerOne.on_chain_start callback: TypeError(\"'NoneType' object is not subscriptable\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_llm_start Ollama\n",
      "on_llm_start (I'm the second handler!!) Ollama\n",
      "on_new_token  我\n",
      "on_new_token 会\n",
      "on_new_token 回答\n",
      "on_new_token 。\n",
      "Final\n",
      "on_new_token  Answer\n",
      "on_new_token :\n",
      "on_new_token  影\n",
      "on_new_token 子\n",
      "on_new_token 之间的\n",
      "on_new_token 吸\n",
      "on_new_token 力\n",
      "on_new_token 主要是\n",
      "on_new_token 由于\n",
      "on_new_token 光\n",
      "on_new_token 的\n",
      "on_new_token 折射\n",
      "on_new_token 和\n",
      "on_new_token 干涉\n",
      "on_new_token 现象\n",
      "on_new_token 引起的\n",
      "on_new_token 。\n",
      "\n",
      "首先\n",
      "on_new_token ，\n",
      "on_new_token 当\n",
      "on_new_token 光线\n",
      "on_new_token 从\n",
      "on_new_token 一种\n",
      "on_new_token 介质\n",
      "on_new_token （\n",
      "on_new_token 如\n",
      "on_new_token 空气\n",
      "on_new_token ）\n",
      "on_new_token 射\n",
      "on_new_token 向\n",
      "on_new_token 另一种\n",
      "on_new_token 介质\n",
      "on_new_token （\n",
      "on_new_token 如\n",
      "on_new_token 水\n",
      "on_new_token ）\n",
      "on_new_token 时\n",
      "on_new_token ，\n",
      "on_new_token 会发生\n",
      "on_new_token 光\n",
      "on_new_token 的\n",
      "on_new_token 反射\n",
      "on_new_token 。\n",
      "on_new_token 在\n",
      "on_new_token 反射\n",
      "on_new_token 过程中\n",
      "on_new_token ，\n",
      "on_new_token 光\n",
      "on_new_token 将\n",
      "on_new_token 一部分\n",
      "on_new_token 能量\n",
      "on_new_token 转化为\n",
      "on_new_token 热量\n",
      "on_new_token ，\n",
      "on_new_token 而\n",
      "on_new_token 另一\n",
      "on_new_token 部分\n",
      "on_new_token 能量\n",
      "on_new_token 则\n",
      "on_new_token 以\n",
      "on_new_token 光\n",
      "on_new_token 的形式\n",
      "on_new_token 返回\n",
      "on_new_token 到\n",
      "on_new_token 空气中\n",
      "on_new_token 。\n",
      "on_new_token 这种\n",
      "on_new_token 过程\n",
      "on_new_token 称为\n",
      "on_new_token 光\n",
      "on_new_token 的\n",
      "on_new_token 反射\n",
      "on_new_token 。\n",
      "\n",
      "接着\n",
      "on_new_token ，\n",
      "on_new_token 当\n",
      "on_new_token 光线\n",
      "on_new_token 继续\n",
      "on_new_token 从\n",
      "on_new_token 一种\n",
      "on_new_token 介质\n",
      "on_new_token 射\n",
      "on_new_token 向\n",
      "on_new_token 另一种\n",
      "on_new_token 介质\n",
      "on_new_token 时\n",
      "on_new_token ，\n",
      "on_new_token 还会\n",
      "on_new_token 发生\n",
      "on_new_token 光\n",
      "on_new_token 的\n",
      "on_new_token 折射\n",
      "on_new_token 现象\n",
      "on_new_token 。\n",
      "on_new_token 在\n",
      "on_new_token 折射\n",
      "on_new_token 过程中\n",
      "on_new_token ，\n",
      "on_new_token 由于\n",
      "on_new_token 不同\n",
      "on_new_token 介质\n",
      "on_new_token 对\n",
      "on_new_token 入\n",
      "on_new_token 射\n",
      "on_new_token 光\n",
      "on_new_token 的\n",
      "on_new_token 折射\n",
      "on_new_token 率\n",
      "on_new_token 不同\n",
      "on_new_token ，\n",
      "on_new_token 因此\n",
      "on_new_token 一部分\n",
      "on_new_token 入\n",
      "on_new_token 射\n",
      "on_new_token 光\n",
      "on_new_token 会\n",
      "on_new_token 改变\n",
      "on_new_token 方向\n",
      "on_new_token ，\n",
      "on_new_token 进入\n",
      "on_new_token 另一种\n",
      "on_new_token 介质\n",
      "on_new_token 中\n",
      "on_new_token 。\n",
      "on_new_token 这种\n",
      "on_new_token 改变\n",
      "on_new_token 方向\n",
      "on_new_token 的\n",
      "on_new_token 入\n",
      "on_new_token 射\n",
      "on_new_token 光\n",
      "on_new_token 就\n",
      "on_new_token 叫做\n",
      "on_new_token 为\n",
      "on_new_token 光\n",
      "on_new_token 的\n",
      "on_new_token 折射\n",
      "on_new_token 。\n",
      "\n",
      "最后\n",
      "on_new_token ，\n",
      "on_new_token 当\n",
      "on_new_token 光线\n",
      "on_new_token 继续\n",
      "on_new_token 从\n",
      "on_new_token 一种\n",
      "on_new_token 介质\n",
      "on_new_token 射\n",
      "on_new_token 向\n",
      "on_new_token 另一种\n",
      "on_new_token 介质\n",
      "on_new_token 时\n",
      "on_new_token ，\n",
      "on_new_token 还会\n",
      "on_new_token 发生\n",
      "on_new_token 光\n",
      "on_new_token 的\n",
      "on_new_token 干涉\n",
      "on_new_token 现象\n",
      "on_new_token 。\n",
      "on_new_token 在\n",
      "on_new_token 干涉\n",
      "on_new_token 过程中\n",
      "on_new_token ，\n",
      "on_new_token 由于\n",
      "on_new_token 不同\n",
      "on_new_token 光源\n",
      "on_new_token 发出\n",
      "on_new_token 的\n",
      "on_new_token 光\n",
      "on_new_token 波\n",
      "on_new_token 具有\n",
      "on_new_token 不同的\n",
      "on_new_token 相\n",
      "on_new_token 位\n",
      "on_new_token 和\n",
      "on_new_token 频率\n",
      "on_new_token 特性\n",
      "on_new_token ，\n",
      "on_new_token 因此\n",
      "on_new_token 一部分\n",
      "on_new_token 入\n",
      "on_new_token 射\n",
      "on_new_token 光\n",
      "on_new_token 会在\n",
      "on_new_token 接收\n",
      "on_new_token 器\n",
      "on_new_token 上\n",
      "on_new_token 产生\n",
      "on_new_token 相\n",
      "on_new_token 位\n",
      "on_new_token 差\n",
      "on_new_token 或\n",
      "on_new_token 频率\n",
      "on_new_token 差\n",
      "on_new_token ，\n",
      "on_new_token 从而\n",
      "on_new_token 导致\n",
      "on_new_token 接收\n",
      "on_new_token 器\n",
      "on_new_token 上的\n",
      "on_new_token 光\n",
      "on_new_token 强\n",
      "on_new_token 发生变化\n",
      "on_new_token 。\n",
      "on_new_token 这种\n",
      "on_new_token 光\n",
      "on_new_token 强\n",
      "on_new_token 变化\n",
      "on_new_token 就是\n",
      "on_new_token 为\n",
      "on_new_token 光\n",
      "on_new_token 的\n",
      "on_new_token 干涉\n",
      "on_new_token 。\n",
      "\n",
      "综\n",
      "on_new_token 上\n",
      "on_new_token 所述\n",
      "on_new_token ，\n",
      "on_new_token 影\n",
      "on_new_token 子\n",
      "on_new_token 之间的\n",
      "on_new_token 吸\n",
      "on_new_token 力\n",
      "on_new_token 主要是\n",
      "on_new_token 由\n",
      "on_new_token 光\n",
      "on_new_token 的\n",
      "on_new_token 反射\n",
      "on_new_token 、\n",
      "on_new_token 折射\n",
      "on_new_token 和\n",
      "on_new_token 干涉\n",
      "on_new_token 现象\n",
      "on_new_token 引起的\n",
      "on_new_token 。\n",
      "on_new_token \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'影子之间的吸力主要是由于光的折射和干涉现象引起的。\\n\\n首先，当光线从一种介质（如空气）射向另一种介质（如水）时，会发生光的反射。在反射过程中，光将一部分能量转化为热量，而另一部分能量则以光的形式返回到空气中。这种过程称为光的反射。\\n\\n接着，当光线继续从一种介质射向另一种介质时，还会发生光的折射现象。在折射过程中，由于不同介质对入射光的折射率不同，因此一部分入射光会改变方向，进入另一种介质中。这种改变方向的入射光就叫做为光的折射。\\n\\n最后，当光线继续从一种介质射向另一种介质时，还会发生光的干涉现象。在干涉过程中，由于不同光源发出的光波具有不同的相位和频率特性，因此一部分入射光会在接收器上产生相位差或频率差，从而导致接收器上的光强发生变化。这种光强变化就是为光的干涉。\\n\\n综上所述，影子之间的吸力主要是由光的反射、折射和干涉现象引起的。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Dict, List, Union\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain_core.agents import AgentAction\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# 定义自定义回调处理器\n",
    "class MyCustomHandlerOne(BaseCallbackHandler):\n",
    "    def on_llm_start(\n",
    "        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any) -> Any:\n",
    "        print(f\"on_llm_start {serialized['name']}\")\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs: Any) -> Any:\n",
    "        print(f\"on_new_token {token}\")\n",
    "\n",
    "    def on_llm_error(\n",
    "        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any ) -> Any:\n",
    "        \"\"\"Run when LLM errors.\"\"\"\n",
    "\n",
    "    def on_chain_start(\n",
    "        self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs: Any) -> Any:\n",
    "        print(f\"on_chain_start {serialized['name']}\")\n",
    "\n",
    "    def on_tool_start(\n",
    "        self, serialized: Dict[str, Any], input_str: str, **kwargs: Any) -> Any:\n",
    "        print(f\"on_tool_start {serialized['name']}\")\n",
    "\n",
    "    def on_agent_action(self, action: AgentAction, **kwargs: Any) -> Any:\n",
    "        print(f\"on_agent_action {action}\")\n",
    "\n",
    "class MyCustomHandlerTwo(BaseCallbackHandler):\n",
    "    def on_llm_start(\n",
    "        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"on_llm_start (I'm the second handler!!) {serialized['name']}\")\n",
    "\n",
    "# 实例化处理器\n",
    "handler1 = MyCustomHandlerOne()\n",
    "handler2 = MyCustomHandlerTwo()\n",
    "\n",
    "# 设置代理。只有“llm”会为handler2发出回调\n",
    "llm = Ollama(model=\"qwen:1.8b\", callbacks=[handler2])\n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n",
    "\n",
    "# handler1的回调将由参与Agent执行的每个对象（llm、llmchain、tool、agent executor）发出\n",
    "agent.run(\"为什么影子之间会有吸力?\", callbacks=[handler1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a43f2-da3a-4c68-8d05-e838db3ed9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
