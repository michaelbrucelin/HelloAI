{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "205b6ef7-ff7f-48e6-adf5-9af77dc2f5dd",
   "metadata": {},
   "source": [
    "# 3. LangChain基础"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d19abb-1255-4614-a39b-18672d37696f",
   "metadata": {},
   "source": [
    "## 3.3. LangChain的回退"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f793a546-af67-4a39-9ec1-dda3414f0834",
   "metadata": {},
   "source": [
    "### 3.3.1. 处理LLM调用API的错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6288b82e-b618-4e6b-b157-3a758476b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import patch\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "import httpx\n",
    "from openai import RateLimitError\n",
    "\n",
    "# 创建一个 RateLimitError 对象\n",
    "response = httpx.Response(\n",
    "    status_code=429,                                                       # 429: Too Many Requests 错误码\n",
    "    request=httpx.Request('GET', 'https://api.openai.com/v1/completions')  # 模拟一个请求对象\n",
    ")\n",
    "\n",
    "body = {\n",
    "    'error': {\n",
    "        'message': 'Rate limit exceeded.',\n",
    "        'type': 'rate_limit_error',\n",
    "        'param': None,\n",
    "        'code': 'rate_limit_error'\n",
    "    }\n",
    "}\n",
    "\n",
    "error = RateLimitError(message=\"Rate limit exceeded.\", response=response, body=body)\n",
    "# print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e40e542-7a1f-45b5-982a-abb6d17a17f6",
   "metadata": {},
   "source": [
    "#### 1. 模拟触发速率限制错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26c96ec-a899-46bf-b3d8-21efd0b588bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "遇到错误\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = 'EMPTY'\n",
    "openai_api_base = 'http://localhost:11434/v1'\n",
    "openai_llm = ChatOpenAI(openai_api_key=openai_api_key, openai_api_base=openai_api_base, temperature=0, max_tokens=256, max_retries=0)\n",
    "\n",
    "with patch(\"openai.resources.chat.completions.Completions.create\", side_effect=error):\n",
    "    try:\n",
    "        print(openai_llm.invoke(\"你是谁？\"))\n",
    "    except RateLimitError:\n",
    "        print(\"遇到错误\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a2cb6-5456-4f7a-b2e8-25bbe9b67a22",
   "metadata": {},
   "source": [
    "#### 2. 测试回退功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e274944-b438-4a10-b999-5971e25aea5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102261/3922159719.py:4: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  qwen_llm = ChatOllama(model=\"qwen:1.8b\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='我是来自阿里云的大规模语言模型，我叫通义千问。我能够理解和生成多种语言，包括但不限于中文、英文、日文等。\\n\\n作为阿里云开发的超大规模语言模型，我可以回答各种问题，提供信息和帮助决策；还可以根据用户提出的问题或指令，进行文本创作，比如写故事、写诗歌、写科技论文等；此外，我还能够实现自动翻译、语音合成、聊天机器人等功能，为用户提供更加智能化和便捷化的服务体验。\\n\\n总之，我是阿里云开发的超大规模语言模型，我具备多种语言理解和生成能力，能够回答各种问题，提供信息和帮助决策；还可以根据用户提出的问题或指令，进行文本创作，比如写故事、写诗歌、写科技论文等；此外，我还能够实现自动翻译、语音合成、聊天机器人等功能，为用户提供更加智能化和便捷化的服务体验。' additional_kwargs={} response_metadata={'model': 'qwen:1.8b', 'created_at': '2025-02-20T09:21:23.70244073Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 44302654905, 'load_duration': 24749125, 'prompt_eval_count': 11, 'prompt_eval_duration': 306000000, 'eval_count': 184, 'eval_duration': 43970000000} id='run-34ecea82-636f-4081-9df4-bcfd9efe8f56-0'\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = 'EMPTY'\n",
    "openai_api_base = 'http://localhost:11434/v1'\n",
    "openai_llm = ChatOpenAI(openai_api_key=openai_api_key, openai_api_base=openai_api_base, temperature=0, max_tokens=256, max_retries=0)\n",
    "qwen_llm = ChatOllama(model=\"qwen:1.8b\")\n",
    "llm = openai_llm.with_fallbacks([qwen_llm])\n",
    "\n",
    "with patch(\"openai.resources.chat.completions.Completions.create\", side_effect=error):\n",
    "    try:\n",
    "        print(llm.invoke(\"你是谁？\"))\n",
    "    except RateLimitError:\n",
    "        print(\"遇到错误\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f006ee-1a7a-46cc-87aa-3676dcb76344",
   "metadata": {},
   "source": [
    "#### 3. 使用具有回退功能的LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a2cbe-9ef1-4fb9-826f-ea473ae89c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"你真是一个贴心的助手，每次回复都会附上赞美之词。\",\n",
    "        ),\n",
    "        (\"human\", \"为什么你喜欢{city}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "with patch(\"openai.resources.chat.completions.Completions.create\", side_effect=error):\n",
    "    try:\n",
    "        print(chain.invoke({\"city\":\"利川\"}))\n",
    "    except RateLimitError:\n",
    "        print(\"Hit error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1def4415-6a23-415c-9502-5678eae30054",
   "metadata": {},
   "source": [
    "### 3.3.2. 处理序列回退"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77c8f4-97be-4714-9e2a-013ff7187104",
   "metadata": {},
   "source": [
    "### 3.3.3. 处理长输入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f445eaa0-3c94-4961-89cd-aad7c17f1bf1",
   "metadata": {},
   "source": [
    "### 3.3.4. 回退到更好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9735c472-8297-4267-837a-7c2039e525cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
